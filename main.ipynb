{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realtime object detection using tensorflow2 and opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites and Installs\n",
    "\n",
    "#### Create a virtual working environment\n",
    "\n",
    "#### Linux\n",
    "Run `python3 -m venv env`\n",
    "Actiate environment `source env/bin/activate`\n",
    "\n",
    "#### Windows\n",
    "Run `python -m venv env`\n",
    "Activate `source env/scripts/activate`\n",
    "\n",
    "#### Install the libraries and modules\n",
    "The following libraries need to be install for the project to run\n",
    "\n",
    "- tensorflow\n",
    "- opencv-python\n",
    "- tensorflow_hub\n",
    "- pandas\n",
    "\n",
    "The packages are also available in the requirements.txt file and can be installed using the command `pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## The libraries can be installed by the following commands when using google colab\n",
    "\n",
    "!pip install tensorflow\n",
    "!pip install opencv-python\n",
    "!pip install tensorflow_hub\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folder tree\n",
    "The Root project tree is as follows\n",
    "\n",
    "![Root folder tree](./input/tree.png)\n",
    "\n",
    "The folder consists of 4 directories and 3 files\n",
    "\n",
    "#### Dirs\n",
    "- env: The virtualenv directory\n",
    "- input: Contains labels.csv\n",
    "- models: Contains the saved_model.pb\n",
    "- output: Contains the sample output screenshots\n",
    "\n",
    "#### Files\n",
    "- main.ipynb : A notebook file that documents and demostrates the code line by line\n",
    "- main.py : A python script version of the notebook file\n",
    "- requirements.txt : a pip dependancy saved file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant libraries installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "detector = hub.load(\"./models\")\n",
    "labels = pd.read_csv('./input/labels.csv',sep=';',index_col='ID')\n",
    "labels = labels['OBJECT (2017 REL.)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable computer camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1080\n",
    "height = 720\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capture frames continually and show the rusulting detected object frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    #Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    #Resize to respect the input_shape\n",
    "    inp = cv2.resize(frame, (width , height ))\n",
    "\n",
    "    #Convert img to RGB\n",
    "    rgb = cv2.cvtColor(inp, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #Is optional but i recommend (float convertion and convert img to tensor image)\n",
    "    rgb_tensor = tf.convert_to_tensor(rgb, dtype=tf.uint8)\n",
    "\n",
    "    #Add dims to rgb_tensor\n",
    "    rgb_tensor = tf.expand_dims(rgb_tensor , 0)\n",
    "    \n",
    "    boxes, scores, classes, num_detections = detector(rgb_tensor)\n",
    "    \n",
    "    pred_labels = classes.numpy().astype('int')[0]\n",
    "    \n",
    "    pred_labels = [labels[i] for i in pred_labels]\n",
    "    pred_boxes = boxes.numpy()[0].astype('int')\n",
    "    pred_scores = scores.numpy()[0]\n",
    "   \n",
    "   #loop throughout the detections and place a box around it  \n",
    "    for score, (ymin,xmin,ymax,xmax), label in zip(pred_scores, pred_boxes, pred_labels):\n",
    "        if score < 0.5:\n",
    "            continue\n",
    "            \n",
    "        score_txt = f'{100 * round(score,0)}'\n",
    "        img_boxes = cv2.rectangle(rgb,(xmin, ymax),(xmax, ymin),(0,255,0),1)      \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img_boxes,label,(xmin, ymax-10), font, 0.5, (255,0,0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(img_boxes,score_txt,(xmax, ymax-10), font, 0.5, (255,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "    #Display the resulting frame\n",
    "    cv2.imshow('black and white',img_boxes)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The output\n",
    "The following are the screenshots of the program in action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Output Frames Screenshot](./output/1.png)\n",
    "![Output Frames Screenshot](./output/2.png)\n",
    "![Output Frames Screenshot](./output/3.png)\n",
    "![Output Frames Screenshot](./output/4.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
